<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="icon.png">
  <title>Guanya Shi</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Guanya Shi 石冠亚</name>
              </p>
              <p>I am a G3 PhD student at the <a href="http://www.cms.caltech.edu/">Department of Computing and Mathematical Sciences</a> in <a href="http://www.caltech.edu">Caltech</a>, advised by Prof. <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a> and <a href="http://www.yisongyue.com/">Yisong Yue</a>. I am also a member of the <a href="http://www.cast.caltech.edu/">Center for Autonomous Systems and Technologies</a> and the <a href="http://dolcit.cms.caltech.edu/">DOLCIT</a>, which is broadly centered around research pertaining statistical decision theory, statistical machine learning, and optimization. I also collaborate closely with Prof. <a href="http://tensorlab.cms.caltech.edu/users/anima/index.html">Anima Anandkumar</a>, <a href="http://users.cms.caltech.edu/~adamw/heavytails.html">Adam Wierman</a> and <a href="http://robotics.caltech.edu/wiki/index.php/JoelBurdick">Joel Burdick</a>. Currently I am working on intersection of machine learning and control theory, and their applications on robotics.
              </p>
              <p>I did my bachelors at <a href="http://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a>. In summer 2016, I was fortunate enough to be selected into <a href="https://engineering.stanford.edu/students-academics/programs/global-engineering-programs/chinese-ugvr">Stanford UGVR program</a>. I was also a ML research intern at <a href="https://www.nvidia.com/en-us/research/">Nvidia AI algorithm group</a> in 2020.
              <!--and worked with Prof. <a href="http://web.stanford.edu/group/tanglab/">Sindy Tang</a>. I've also spent time at <a href="https://www.sensetime.com/">Sensetime</a> as deep learning research intern, supervised by <a href="http://shijianping.me">Jianping Shi</a>.-->
              </p>
              <p align=center>
		<a href="https://drive.google.com/open?id=1933oz0ZgajvrYgntX8sUXIpOiLviYtxg">CV</a> &nbsp/&nbsp
                <a href="mailto:gshi@caltech.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/GuanyaShi">GitHub</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=joR1Z4UAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/GuanyaShi">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/guanya-shi-b07b43126"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="GuanyaPhoto_small.png">
            </td>
          </tr>
        </table>
        
        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p>
                <strong style="color:red;">News:</strong> I am co-planning <papertitle>Control Meets Learning</papertitle>, a virtual seminar series on the intersection of control and learning (coming soon).  
              </p>
              <p>
                <strong style="color:red;">News:</strong> Our Neural Swarm paper was accepted by <a href="https://www.icra2019.org">ICRA 2020</a> and highlighed by <a href="https://www.caltech.edu/about/news/machine-learning-helps-robot-swarms-coordinate">Caltech</a> and <a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html">Yahoo news</a>.
              </p>
              <p>
                <strong style="color:red;">News:</strong> Interviewed by Facebook PyTorch team about learning and control research in robotic systems. [<a href="https://youtu.be/se206WBk2dM">video</a>]
              </p>
              <p>
                <strong style="color:red;">News:</strong> Our work on Neural Lander was accepted by <a href="https://www.icra2019.org">ICRA 2019</a> and reported by <a href="https://www.caltech.edu/about/news/neural-lander-uses-ai-land-drones-smoothly">Caltech homepage</a>.
              </p>
	            <!--<p>
                <strong style="color:red;">News:</strong> Our work on Neural Lander was presented in <a href="http://phys2018.csail.mit.edu">Physics Workshop at NeurIPS 2018</a>.-->
              </p>    
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research and Selected Publications</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle>Neural-Lander Family: Learning Based Nonlinear Provably Stable Control in Multi-Agent and Changing Environments</papertitle>
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='neural_lander.png' width=100%>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/1811.08027">
                  <papertitle>Neural Lander: Stable Drone Landing Control using Learned Dynamics</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi</a>, <a href="https://www.linkedin.com/in/mtoc12/">Michael O'Connell</a>, <a href="http://roseyu.com/">Rose Yu</a>, <a href="https://scholar.google.com/citations?user=CxAS4SQAAAAJ&hl=en">Kamyar Azizzadenesheli</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
                <br>
                [<a href="https://arxiv.org/abs/1811.08027">arXiv</a>]
                [<a href="https://youtu.be/FLLsG0S78ik">video</a>]
                [<a href="https://www.caltech.edu/about/news/neural-lander-uses-ai-land-drones-smoothly">Caltech homepage news</a>]
                [<a href="https://us13.campaign-archive.com/?u=67bd06787e84d73db24fb0aa5&id=6d61d65ae0&e=b8f2a6be0d">highlighted by Import AI</a>]
                <br>
                <p></p>
                <p>We present a novel deep-learning-based robust nonlinear controller for stable quadrotor control during landing. Our approach blends together a nominal dynamics model coupled with a DNN that learns the high-order interactions, such as the complex interactions between the ground and multi-rotor airflow. To the best of our knowledge, this is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. 
                </p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='neural_swarm_new.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://drive.google.com/open?id=1B3G9OcLuAbenaPju3-ZPJSB1JxbBPCv-">
                  <papertitle>Neural-Swarm: Heterogeneous Multi-Robot Control and Planning Using Learned Interactions</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://scholar.google.com/citations?user=XUQcbFAAAAAJ&hl=en">Wolfgang Hoenig</a>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>International Conference on Robotics and Automation (ICRA)</em>, 2020
                <br>
                Journal version submitted to <em>IEEE Transactions on Robotics</em>
                <br>
                [<a href="https://authors.library.caltech.edu/99548/2/ICRA_2020_Neural_Swarm.pdf">pdf</a>]
                [<a href="https://youtu.be/v4j-9pH11Q8">video</a>]
                [<a href="https://www.caltech.edu/about/news/machine-learning-helps-robot-swarms-coordinate">Caltech news</a>]
                [<a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html">Yahoo news</a>]
                <br>
                <p></p>
                <p>Close-proximity control and planning are challenging due to the complex aerodynamic interaction effects between multirotors. We proposed Neural-Swarm, a non-linear decentralized stable learning-based controller and motion planner for close-proximity flight of heterogeneous multirotor swarms. We employ heterogeneous deep sets to encode multi-vehicle interactions in an index-free manner, enabling better generalization to new formations andvarying number of vehicles.</p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='meta_learning.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://drive.google.com/open?id=1no4olzlgqA7kc60b7V2pkXqFjxY2H3Ds">
                  <papertitle>Neural-Fly: Meta-Learning-Based Robust Adaptive Flight Control under Uncertain Wind Conditions</papertitle>
                </a>
                <br>
                <a href="https://www.linkedin.com/in/mtoc12/">Michael O'Connell</a>, <strong>Guanya Shi</strong>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <!--<em>Submitted to ICRA 2020</em>-->
                <!--
                <br>
                <a href="https://drive.google.com/open?id=1WgW6Ym84dxv95-KQQy5X27W5kFNp7KMq">[<strong>video</strong>]</a>
                <a href="https://drive.google.com/open?id=1no4olzlgqA7kc60b7V2pkXqFjxY2H3Ds">[<strong>pdf</strong>]</a>
                <br>-->
                <p></p>
                <p>Realtime model learning proves challenging for complex dynamical  systems. Deep learning has high representation power but is often too slow to update  onboard. On the other hand, adaptive control relies on simple linear parameter models can update as fast as the feedback control loop. We  propose an online composite adaptation method that treats outputs from a deep  neural network as a set of basis functions capable of representing different wind conditions. Meta-learning techniques are used to optimize the network such that the last layer is fast for adaptation. We validate our approach by  flying a drone in an open air wind tunnel under varying wind conditions.</p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle>Neural-Lander Family: Learning Based Nonlinear Provably Stable Control in Multi-Agent and Changing Environments</papertitle>
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='optimistic_robd.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://drive.google.com/open?id=1B3G9OcLuAbenaPju3-ZPJSB1JxbBPCv-">
                  <papertitle>Beyond No-Regret: Competitive Control via Online Optimization with Memory</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://scholar.google.com/citations?user=S1wSEggAAAAJ&hl=en">Yiheng Lin</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://users.cms.caltech.edu/~adamw/index.html">Adam Wierman</a>
                <br>
                <em>arXiv preprint</em>
                <br>
                [<a href="https://arxiv.org/abs/2002.05318">arXiv</a>]
                <br>
                <p></p>
                <p>This paper studies online control with adversarial disturbances using tools from online optimization with memory. Most work that bridges learning and control theory focuses on designing policies that are no-regret with respect to the best static linear controller in hindsight. However, the optimal offline controller can have orders-of-magnitude lower cost than the best linear controller. We instead focus on achieving constant competitive ratio compared to the offline optimal controller, which need not be linear or static. We provide a novel reduction from online control to online convex optimization with memory. We then design a new algorithm for online convex optimization with memory, Optimistic Regularized Online Balanced Descent, that has a constant, dimension-free competitive ratio. This result, in turn, leads to a new constant-competitive approach for online control.</p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle>Neural-Lander Family: Learning Based Nonlinear Provably Stable Control in Multi-Agent and Changing Environments</papertitle>
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='robust_regression.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/pdf/1906.05819">
                  <papertitle>Robust Regression for Safe Exploration in Control</papertitle>
                </a>
                <br>
                <a href="https://anqiliu-ai.github.io">Anqi Liu</a>, <strong>Guanya Shi</strong>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>
                <br>
                <em>Conference on Learning for Dynamics and Control (L4DC)</em>, 2020
                <br>
                [<a href="https://arxiv.org/pdf/1906.05819">arXiv</a>]
                <br>
                <p></p>
                <p>We study the problem of safe learning and exploration in sequential control problems. A central challenge in this setting is how to quantify uncertainty in order to choose provably-safe actions that allow us to collect useful data and reduce uncertainty. We present a deep robust regression model that is trained to directly predict the uncertainty bounds for safe exploration. We then show how to integrate our robust regression approach with model-based control methods by learning a dynamic model with robustness bounds. We demonstrate empirically that our robust regression approach can outperform conventional Gaussian process (GP) based safe exploration.</p>
            </td>
          </tr>

          </table>

        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            <a href="http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html">
                  <papertitle>CS/CNS/EE/IDS 165: Foundations of Machine Learning and Statistical Inference, Caltech</papertitle></a>
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Talks and Activities</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            Interviewed by Facebook PyTorch team about learning and control research in robotic systems. [<a href="https://youtu.be/se206WBk2dM">video</a>]
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Conference and Journal Reviewing</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            <papertitle>Conference:</papertitle> ICML 2020, NeurIPS 2020, ICRA 2019-2020, IROS 2020, ICLR 2021
            </p>
            <p>
            <papertitle>Journal:</papertitle> IEEE Transaction on Automatic Control (TAC)
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Course Projects</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="mario.png" alt="prl" width="190" height="190"></td>
            <td width="75%" valign="top">
              <p>
                <a href="https://github.com/GuanyaShi/Training-DQN-to-play-Super-Mario-Bros">
                  <papertitle>Teaching Mario to Play Mario: Reinforcement Learning on <em>Super Mario Bros</em>.</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://sites.google.com/view/botaohu">Botao Hu</a>, <a href="https://www.linkedin.com/in/echoyw/">Yan Wu</a>
                <p>
                  <br> Final project of <a href="https://sites.google.com/view/cs-159-spring-2018/home">Caltech CS 159</a>. We present a deep learning model to successfully learn control policies from high-dimensional input data using reinforcement learning. The model is based on the idea of Deep Q-Network (DQN), with convolutional neural network trained by Q-learning algorithm, whose input is tile representation of the screen and output is a value estimation function. Also, replay buffer, target network and double Q-learning are applied to lower data dependency and approximate real gradiant descent.
                </p>
              </p>
            </td>
          </tr>
        </table>
  
        <hr>
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Hobbies</heading>
              <p>
                I love playing basketball, soccer and MOBA games. I am also very interested in photography, hiking, travelling and cooking. Here are some pictures by me.
<!--                 Representative papers are <span class="highlight">highlighted</span>.
 -->          </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="1.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="10.jpg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Winter Tsinghua</td>
            <td width="50%" align="center">Beckman Auditorium, Caltech</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="3.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="4.jpeg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Beijing National Stadium</td>
            <td width="50%" align="center">Catalina Island</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="5.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="6.jpeg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Wudaokou, Beijing</td>
            <td width="50%" align="center">Tokugawaen, Nagoya, Japan</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="9.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="8.jpeg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Santa Monica, California</td>
            <td width="50%" align="center">Yosemite, California</td>
        </table>

        <hr>
  
        <table width="80%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="left">
                <font size="2">
                  Based on <a href="https://jonbarron.info/">this website</a>.
                  </font>
              </p>
            </td>
          </tr>
        </table>
        <table width="20%" align="right" border="0" cellspacing="0" cellpadding="20">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=UeP4z9v03sHtkGGcNgcJaLLOYl7Tm5OQqbSpW6HSGcI&cl=ffffff&w=a"></script>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
